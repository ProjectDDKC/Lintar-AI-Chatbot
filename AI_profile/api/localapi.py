import json
from save import save_engine as save 
import requests
import json

configapi = {
    "api_url":"http://localhost:5001/v1/chat/completions", 
    "api_key":"4501650",
    "model":"Lintar",
    "temperature": 0.8,
    "max_tokens": 500
}

def localapi():
    configapi["api_url"] = save.loader["api_url"]
    with open("AI_profile/configapi.json", "w") as file:
        json.dump(configapi, file, indent=4)

CONFIG_API = "AI_profile/configapi.json"
PROMPT = "AI_profile/Prompt.json"
CHAT_MEMORY_PATH = "AI_profile/chat_memory.json"
MAX_MEMORY = 5  # ‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏Å‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î memory
def load_recent_memory(path=CHAT_MEMORY_PATH, limit=MAX_MEMORY):
    try:
        with open(path, "r", encoding="utf-8") as f:
            history = json.load(f)
            return history[-limit:]
    except FileNotFoundError:
        return []

def save_message(role, content, path=CHAT_MEMORY_PATH):
    try:
        with open(path, "r", encoding="utf-8") as f:
            history = json.load(f)
    except FileNotFoundError:
        history = []

    history.append({"role": role, "content": content})
    with open(path, "w", encoding="utf-8") as f:
        json.dump(history, f, indent=2, ensure_ascii=False)

# ‚úÖ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å
def chat_with_local(text):
    with open(CONFIG_API, "r", encoding="utf-8") as f:
        config = json.load(f)

    with open(PROMPT, "r", encoding="utf-8") as f:
        prompt = json.load(f)

    print(text)

    headers = {
        "Authorization": f"Bearer {config['api_key']}",
        "Content-Type": "application/json"
    }

    # üß† ‡∏î‡∏∂‡∏á memory ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö prompt
    messages = prompt["system_prompts"][:] #‡∏î‡∏∂‡∏á prompt ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ system ‡πÑ‡∏ß‡πâ
    messages += load_recent_memory() #‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    messages.append({"role": "user", "content": text}) #‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏°‡∏≤ 

    payload = {
        "model": config["model"],
        "messages": messages,
        "temperature": config["temperature"],
        "max_tokens": config["max_tokens"]
    }

    try:
        response = requests.post(config["api_url"], headers=headers, json=payload)
        print(payload)
        response_data = response.json()
        ai_response = response_data["choices"][0]["message"]["content"].strip()

        save_message("user", text)
        save_message("assistant", ai_response)

        return ai_response
    except Exception as e:
        return f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ LLM API (HTTP Error) ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Link API HTTP"